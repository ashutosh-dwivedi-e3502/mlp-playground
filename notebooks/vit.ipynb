{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black\n",
    "\n",
    "import notebooks_path\n",
    "\n",
    "notebooks_path.include_packages()\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import optax\n",
    "import equinox as eqx\n",
    "\n",
    "from vit import dataloader, util, model, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = dataloader.get_train_dataloader(batch_size)\n",
    "test_datalodeer = dataloader.get_test_dataloader(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = next(iter(test_datalodeer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "jax_image = jnp.array(image[0][0].numpy())\n",
    "print(jax_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = util.img_to_patches(jax_image, patch_size=16, flatten_channel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "util.plot_patches(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = util.img_to_patches(jax_image, patch_size=16, flatten_channel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lr = 0.0001\n",
    "dropout_rate = 0.1\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "batch_size = 64\n",
    "patch_size = 4\n",
    "num_patches = 64\n",
    "num_steps = 100000\n",
    "image_size = (32, 32, 3)\n",
    "embedding_dim = 512\n",
    "hidden_dim = 256\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "height, width, channels = image_size\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "vmap got inconsistent sizes for array axes to be mapped:\n  * one axis had size 8: axis 0 of argument x of type float32[8,3,32,32];\n  * one axis had size 64: axis 0 of argument key of type uint32[64,2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m\n\u001b[1;32m     16\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39madamw(\n\u001b[1;32m     17\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m     18\u001b[0m     b1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m     19\u001b[0m     b2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m state \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39minit(eqx\u001b[38;5;241m.\u001b[39mfilter(model_obj, eqx\u001b[38;5;241m.\u001b[39mis_inexact_array))\n\u001b[0;32m---> 24\u001b[0m model, _obj, state, losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mlp-playground/playground/vit/train.py:62\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, state, data_loader, batch_size, num_steps, print_every, key)\u001b[0m\n\u001b[1;32m     59\u001b[0m key, \u001b[38;5;241m*\u001b[39msubkeys \u001b[38;5;241m=\u001b[39m jr\u001b[38;5;241m.\u001b[39msplit(key, num\u001b[38;5;241m=\u001b[39mbatch_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     60\u001b[0m subkeys \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marray(subkeys)\n\u001b[0;32m---> 62\u001b[0m (model, state, loss) \u001b[38;5;241m=\u001b[39m \u001b[43mstep_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubkeys\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (step \u001b[38;5;241m%\u001b[39m print_every) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m step \u001b[38;5;241m==\u001b[39m num_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "    \u001b[0;31m[... skipping hidden 16 frame]\u001b[0m\n",
      "File \u001b[0;32m~/mlp-playground/playground/vit/train.py:29\u001b[0m, in \u001b[0;36mstep_model\u001b[0;34m(model, optimizer, state, images, labels, key)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@eqx\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_jit\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_model\u001b[39m(\n\u001b[1;32m     22\u001b[0m     model: VisionTransformer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     key,\n\u001b[1;32m     28\u001b[0m ):\n\u001b[0;32m---> 29\u001b[0m     loss, grads \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     updates, new_state \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mupdate(grads, state, model)\n\u001b[1;32m     32\u001b[0m     model \u001b[38;5;241m=\u001b[39m eqx\u001b[38;5;241m.\u001b[39mapply_updates(model, updates)\n",
      "    \u001b[0;31m[... skipping hidden 10 frame]\u001b[0m\n",
      "File \u001b[0;32m~/mlp-playground/playground/vit/train.py:14\u001b[0m, in \u001b[0;36mcompute_grads\u001b[0;34m(model, images, labels, key)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;129m@eqx\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_value_and_grad\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_grads\u001b[39m(\n\u001b[1;32m     12\u001b[0m     model: VisionTransformer, images: jnp\u001b[38;5;241m.\u001b[39mndarray, labels: jnp\u001b[38;5;241m.\u001b[39mndarray, key\n\u001b[1;32m     13\u001b[0m ):\n\u001b[0;32m---> 14\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39msoftmax_cross_entropy_with_integer_labels(logits, labels)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mmean(loss)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/jax/_src/api.py:1340\u001b[0m, in \u001b[0;36m_mapped_axis_size\u001b[0;34m(fn, tree, vals, dims, name)\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1339\u001b[0m     msg\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  * some axes (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mct\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of them) had size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msz\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, e.g. axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00max\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(msg)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: vmap got inconsistent sizes for array axes to be mapped:\n  * one axis had size 8: axis 0 of argument x of type float32[8,3,32,32];\n  * one axis had size 64: axis 0 of argument key of type uint32[64,2]"
     ]
    }
   ],
   "source": [
    "key = jr.PRNGKey(2003)\n",
    "\n",
    "model_obj = model.VisionTransformer(\n",
    "    embedding_dim=embedding_dim,\n",
    "    channels=channels,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    dropout_rate=dropout_rate,\n",
    "    patch_size=patch_size,\n",
    "    num_patches=num_patches,\n",
    "    num_classes=num_classes,\n",
    "    key=key,\n",
    ")\n",
    "\n",
    "optimizer = optax.adamw(\n",
    "    learning_rate=lr,\n",
    "    b1=beta1,\n",
    "    b2=beta2,\n",
    ")\n",
    "\n",
    "state = optimizer.init(eqx.filter(model_obj, eqx.is_inexact_array))\n",
    "\n",
    "model, _obj, state, losses = train.train(\n",
    "    model_obj, optimizer, state, train_dataloader, batch_size, num_steps, key=key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
