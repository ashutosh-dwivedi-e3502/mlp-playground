{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(eqx.Module):\n",
    "    weight: jax.Array\n",
    "    bias: jax.Array\n",
    "\n",
    "    def __init__(self, in_size, out_size, key):\n",
    "        wkey, bkey = jax.random.split(key)\n",
    "        self.weight = jax.random.normal(wkey, (out_size, in_size))\n",
    "        self.bias = jax.random.normal(bkey, (out_size,))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.weight @ x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "@jax.grad\n",
    "def loss_fn(model, x, y):\n",
    "    pred_y = jax.vmap(model)(x)\n",
    "    return jax.numpy.mean((y - pred_y) ** 2)\n",
    "\n",
    "batch_size, in_size, out_size = 32, 2, 3\n",
    "model = Linear(in_size, out_size, key=jax.random.PRNGKey(0))\n",
    "x = jax.numpy.zeros((batch_size, in_size))\n",
    "y = jax.numpy.zeros((batch_size, out_size))\n",
    "grads = loss_fn(model, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0meqx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0meps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mchannelwise_affine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmomentum\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minference\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'jax.numpy.float32'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Computes a mean and standard deviation over the batch and spatial\n",
      "dimensions of an array, and uses these to normalise the whole array. Optionally\n",
      "applies a channelwise affine transformation afterwards.\n",
      "\n",
      "Given an input array $x = [x_1, ... x_C]$ with $C$ channels, this layer computes\n",
      "\n",
      "$$\\frac{x_i - \\mathbb{E}[x_i]}{\\sqrt{\\text{Var}[x_i] + \\varepsilon}} * \\gamma_i + \\beta_i$$\n",
      "\n",
      "for all $i$. Here $*$ denotes elementwise multiplication and $\\gamma$, $\\beta$ have\n",
      "shape $(C,)$ if `channelwise_affine=True` and $\\gamma = 1$, $\\beta = 0$ if\n",
      "`channelwise_affine=False`. Expectations are computed over all spatial dimensions\n",
      "*and* over the batch dimension, and updated batch-by-batch according to `momentum`.\n",
      "\n",
      "!!! example\n",
      "\n",
      "    See [this example](../../examples/stateful.ipynb) for example usage.\n",
      "\n",
      "!!! warning\n",
      "\n",
      "    This layer must be used inside of a `vmap` or `pmap` with a matching\n",
      "    `axis_name`. (Not doing so will raise a `NameError`.)\n",
      "\n",
      "Note that this layer behaves differently during training and inference. During\n",
      "training then statistics are computed using the input data, and the running\n",
      "statistics updated. During inference then just the running statistics are used.\n",
      "Whether the model is in training or inference mode should be toggled using\n",
      "[`equinox.nn.inference_mode`][].\n",
      "\u001b[0;31mInit docstring:\u001b[0m\n",
      "**Arguments:**\n",
      "\n",
      "- `input_size`: The number of channels in the input array.\n",
      "- `axis_name`: The name of the batch axis to compute statistics over, as passed\n",
      "    to `axis_name` in `jax.vmap` or `jax.pmap`. Can also be a sequence (e.g. a\n",
      "    tuple or a list) of names, to compute statistics over multiple named axes.\n",
      "- `eps`: Value added to the denominator for numerical stability.\n",
      "- `channelwise_affine`: Whether the module has learnable channel-wise affine\n",
      "    parameters.\n",
      "- `momentum`: The rate at which to update the running statistics. Should be a\n",
      "    value between 0 and 1 exclusive.\n",
      "- `inference`: If `False` then the batch means and variances will be calculated\n",
      "    and used to update the running statistics. If `True` then the running\n",
      "    statistics are directly used for normalisation. This may be toggled with\n",
      "    [`equinox.nn.inference_mode`][] or overridden during\n",
      "    [`equinox.nn.BatchNorm.__call__`][].\n",
      "- `dtype`: The dtype of the input array.\n",
      "\u001b[0;31mFile:\u001b[0m           /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/equinox/nn/_batch_norm.py\n",
      "\u001b[0;31mType:\u001b[0m           _ModuleMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?eqx.nn.BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CpuDevice(id=0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import STL10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/teamspace/studios/this_studio/temp_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_stl_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m unlabeled_data, train_data_contrast \u001b[39m=\u001b[39m get_stl_dataset(path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_stl_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "unlabeled_data, train_data_contrast = get_stl_dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
